{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453f9792",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas openpyxl scikit-learn xgboost lightgbm shap matplotlib seaborn scikit-posthocs joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1caebd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All directories are created or already exist.\n",
      "Source data for EDA saved to: /home/sajad/Sajad_test/Pistachio Dataset/data_results\n",
      "\n",
      "Dataset loaded successfully. Column names cleaned.\n",
      "    area  perimeter  major_axis  minor_axis  eccentricity   eqdiasq  solidity  \\\n",
      "0  63391   1568.405    390.3396    236.7461        0.7951  284.0984    0.8665   \n",
      "1  68358   1942.187    410.8594    234.7525        0.8207  295.0188    0.8765   \n",
      "2  73589   1246.538    452.3630    220.5547        0.8731  306.0987    0.9172   \n",
      "3  71106   1445.261    429.5291    216.0765        0.8643  300.8903    0.9589   \n",
      "4  80087   1251.524    469.3783    220.9344        0.8823  319.3273    0.9657   \n",
      "\n",
      "   convex_area  extent  aspect_ratio  ...  stddev_rr  stddev_rg  stddev_rb  \\\n",
      "0        73160  0.6394        1.6488  ...    17.7206    19.6024    21.1342   \n",
      "1        77991  0.6772        1.7502  ...    26.7061    27.2112    25.1035   \n",
      "2        80234  0.7127        2.0510  ...    19.0129    20.0703    20.7006   \n",
      "3        74153  0.7028        1.9879  ...    18.1773    18.7152    29.7883   \n",
      "4        82929  0.7459        2.1245  ...    23.4298    24.0878    23.1157   \n",
      "\n",
      "   skew_rr  skew_rg  skew_rb  kurtosis_rr  kurtosis_rg  kurtosis_rb  \\\n",
      "0   0.4581   0.6635   0.7591       2.9692       3.0576       2.9542   \n",
      "1  -0.3847  -0.2713  -0.2927       1.9807       2.1006       2.2152   \n",
      "2  -0.6014  -0.4500   0.2998       3.5420       3.6856       4.1012   \n",
      "3  -0.6943  -0.6278  -0.7798       2.8776       2.8748       2.8953   \n",
      "4  -0.9287  -0.8134  -0.4970       2.9915       2.8813       2.7362   \n",
      "\n",
      "               class  \n",
      "0  Kirmizi_Pistachio  \n",
      "1  Kirmizi_Pistachio  \n",
      "2  Kirmizi_Pistachio  \n",
      "3  Kirmizi_Pistachio  \n",
      "4  Kirmizi_Pistachio  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "\n",
      "============================================================\n",
      "Step 1: Starting Exploratory Data Analysis (EDA)\n",
      "============================================================\n",
      "\n",
      "Descriptive statistics saved to EDA and data_results folders.\n",
      "\n",
      "Generating Box Plots...\n",
      "Plot saved: boxplot_area.svg and boxplot_area.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_perimeter.svg and boxplot_perimeter.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_major_axis.svg and boxplot_major_axis.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_minor_axis.svg and boxplot_minor_axis.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_eccentricity.svg and boxplot_eccentricity.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_eqdiasq.svg and boxplot_eqdiasq.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_solidity.svg and boxplot_solidity.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_convex_area.svg and boxplot_convex_area.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_extent.svg and boxplot_extent.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_aspect_ratio.svg and boxplot_aspect_ratio.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_roundness.svg and boxplot_roundness.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_compactness.svg and boxplot_compactness.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_shapefactor_1.svg and boxplot_shapefactor_1.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_shapefactor_2.svg and boxplot_shapefactor_2.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_shapefactor_3.svg and boxplot_shapefactor_3.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_shapefactor_4.svg and boxplot_shapefactor_4.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_mean_rr.svg and boxplot_mean_rr.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_mean_rg.svg and boxplot_mean_rg.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_mean_rb.svg and boxplot_mean_rb.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_stddev_rr.svg and boxplot_stddev_rr.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_stddev_rg.svg and boxplot_stddev_rg.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_stddev_rb.svg and boxplot_stddev_rb.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_skew_rr.svg and boxplot_skew_rr.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_skew_rg.svg and boxplot_skew_rg.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_skew_rb.svg and boxplot_skew_rb.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_kurtosis_rr.svg and boxplot_kurtosis_rr.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_kurtosis_rg.svg and boxplot_kurtosis_rg.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: boxplot_kurtosis_rb.svg and boxplot_kurtosis_rb.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "\n",
      "Generating Correlation Matrix...\n",
      "Correlation matrix data saved to: /home/sajad/Sajad_test/Pistachio Dataset/data_results\n",
      "Plot saved: correlation_heatmap.svg and correlation_heatmap.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "\n",
      "Generating Distribution Plots...\n",
      "Plot saved: distribution_area.svg and distribution_area.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_perimeter.svg and distribution_perimeter.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_major_axis.svg and distribution_major_axis.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_minor_axis.svg and distribution_minor_axis.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_eccentricity.svg and distribution_eccentricity.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_eqdiasq.svg and distribution_eqdiasq.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_solidity.svg and distribution_solidity.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_convex_area.svg and distribution_convex_area.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_extent.svg and distribution_extent.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_aspect_ratio.svg and distribution_aspect_ratio.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_roundness.svg and distribution_roundness.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_compactness.svg and distribution_compactness.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_shapefactor_1.svg and distribution_shapefactor_1.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_shapefactor_2.svg and distribution_shapefactor_2.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_shapefactor_3.svg and distribution_shapefactor_3.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_shapefactor_4.svg and distribution_shapefactor_4.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_mean_rr.svg and distribution_mean_rr.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_mean_rg.svg and distribution_mean_rg.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_mean_rb.svg and distribution_mean_rb.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_stddev_rr.svg and distribution_stddev_rr.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_stddev_rg.svg and distribution_stddev_rg.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_stddev_rb.svg and distribution_stddev_rb.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_skew_rr.svg and distribution_skew_rr.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_skew_rg.svg and distribution_skew_rg.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_skew_rb.svg and distribution_skew_rb.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_kurtosis_rr.svg and distribution_kurtosis_rr.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_kurtosis_rg.svg and distribution_kurtosis_rg.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "Plot saved: distribution_kurtosis_rb.svg and distribution_kurtosis_rb.pdf in /home/sajad/Sajad_test/Pistachio Dataset/EDA\n",
      "\n",
      "EDA Step Completed.\n",
      "\n",
      "============================================================\n",
      "Step 2: Starting Statistical Analysis\n",
      "============================================================\n",
      "\n",
      "Statistical analysis completed. All result data saved to data_results folder.\n",
      "\n",
      "============================================================\n",
      "Step 3: Starting Machine Learning Modeling\n",
      "============================================================\n",
      "\n",
      "Target classes encoded and encoder saved: ['Kirmizi_Pistachio', 'Siirt_Pistachio'] -> [0, 1]\n",
      "\n",
      "Unscaled test data and scaler saved for re-plotting purposes.\n",
      "\n",
      "--- Processing Model: Logistic_Regression ---\n",
      "Evaluation metrics and model saved for Logistic_Regression.\n",
      "Plot saved: Logistic_Regression_confusion_matrix.svg and Logistic_Regression_confusion_matrix.pdf in /home/sajad/Sajad_test/Pistachio Dataset/Logistic_Regression\n",
      "Performing SHAP analysis for Logistic_Regression...\n",
      "Plot saved: Logistic_Regression_shap_summary_plot.svg and Logistic_Regression_shap_summary_plot.pdf in /home/sajad/Sajad_test/Pistachio Dataset/Logistic_Regression\n",
      "\n",
      "--- Processing Model: Random_Forest ---\n",
      "Evaluation metrics and model saved for Random_Forest.\n",
      "Plot saved: Random_Forest_confusion_matrix.svg and Random_Forest_confusion_matrix.pdf in /home/sajad/Sajad_test/Pistachio Dataset/Random_Forest\n",
      "Performing SHAP analysis for Random_Forest...\n",
      "Plot saved: Random_Forest_shap_summary_plot.svg and Random_Forest_shap_summary_plot.pdf in /home/sajad/Sajad_test/Pistachio Dataset/Random_Forest\n",
      "\n",
      "--- Processing Model: XGBoost ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sajad/miniconda3/envs/sajad/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [10:29:42] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics and model saved for XGBoost.\n",
      "Plot saved: XGBoost_confusion_matrix.svg and XGBoost_confusion_matrix.pdf in /home/sajad/Sajad_test/Pistachio Dataset/XGBoost\n",
      "Performing SHAP analysis for XGBoost...\n",
      "Plot saved: XGBoost_shap_summary_plot.svg and XGBoost_shap_summary_plot.pdf in /home/sajad/Sajad_test/Pistachio Dataset/XGBoost\n",
      "\n",
      "--- Processing Model: LightGBM ---\n",
      "[LightGBM] [Info] Number of positive: 733, number of negative: 985\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6695\n",
      "[LightGBM] [Info] Number of data points in the train set: 1718, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.426659 -> initscore=-0.295496\n",
      "[LightGBM] [Info] Start training from score -0.295496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sajad/miniconda3/envs/sajad/lib/python3.11/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/sajad/miniconda3/envs/sajad/lib/python3.11/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/sajad/miniconda3/envs/sajad/lib/python3.11/site-packages/shap/explainers/_tree.py:587: UserWarning: LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics and model saved for LightGBM.\n",
      "Plot saved: LightGBM_confusion_matrix.svg and LightGBM_confusion_matrix.pdf in /home/sajad/Sajad_test/Pistachio Dataset/LightGBM\n",
      "Performing SHAP analysis for LightGBM...\n",
      "Plot saved: LightGBM_shap_summary_plot.svg and LightGBM_shap_summary_plot.pdf in /home/sajad/Sajad_test/Pistachio Dataset/LightGBM\n",
      "\n",
      "Machine Learning modeling step completed.\n",
      "\n",
      "============================================================\n",
      "Step 4: Starting Model Comparison\n",
      "============================================================\n",
      "Comparison metrics data saved.\n",
      "                     Accuracy  Precision    Recall  F1-score  Cohen's Kappa  \\\n",
      "Model                                                                         \n",
      "Logistic_Regression  0.909302   0.909091  0.874317  0.891365       0.813571   \n",
      "Random_Forest        0.893023   0.882682  0.863388  0.872928       0.780578   \n",
      "XGBoost              0.923256   0.916667  0.901639  0.909091       0.842700   \n",
      "LightGBM             0.927907   0.922222  0.907104  0.914601       0.852234   \n",
      "\n",
      "                     Matthews Corr Coef   ROC AUC  \n",
      "Model                                              \n",
      "Logistic_Regression            0.814027  0.971461  \n",
      "Random_Forest                  0.780720  0.947922  \n",
      "XGBoost                        0.842787  0.976770  \n",
      "LightGBM                       0.852321  0.974315  \n",
      "Plot saved: models_metrics_comparison_bar_chart.svg and models_metrics_comparison_bar_chart.pdf in /home/sajad/Sajad_test/Pistachio Dataset/compairation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sajad/miniconda3/envs/sajad/lib/python3.11/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/sajad/miniconda3/envs/sajad/lib/python3.11/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: all_models_roc_curves.svg and all_models_roc_curves.pdf in /home/sajad/Sajad_test/Pistachio Dataset/compairation\n",
      "\n",
      "Generating Comparative Precision-Recall Curves...\n",
      "Plot saved: all_models_pr_curves.svg and all_models_pr_curves.pdf in /home/sajad/Sajad_test/Pistachio Dataset/compairation\n",
      "\n",
      "Model comparison step completed.\n",
      "\n",
      "============================================================\n",
      "SCRIPT EXECUTION FINISHED SUCCESSFULLY!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# کد 1: اسکریپت اصلی تحلیل دیتاست پسته\n",
    "# ==============================================================================\n",
    "\n",
    "# Step 0: Setup and Initial Loading\n",
    "# ==============================================================================\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import joblib\n",
    "import shap\n",
    "from scipy.stats import shapiro, f_oneway, kruskal\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# Machine Learning models and metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    cohen_kappa_score, matthews_corrcoef, confusion_matrix,\n",
    "    roc_curve, auc, roc_auc_score,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# --- Configuration ---\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# --- Define Paths ---\n",
    "BASE_PATH = '/home/sajad/Sajad_test/Pistachio Dataset/'\n",
    "DATA_PATH = os.path.join(BASE_PATH, 'dataset/Pistachio_28_Features_Dataset.xlsx')\n",
    "EDA_PATH = os.path.join(BASE_PATH, 'EDA')\n",
    "STATS_PATH = os.path.join(BASE_PATH, 'Statistical_Analysis')\n",
    "LR_PATH = os.path.join(BASE_PATH, 'Logistic_Regression')\n",
    "RF_PATH = os.path.join(BASE_PATH, 'Random_Forest')\n",
    "XGB_PATH = os.path.join(BASE_PATH, 'XGBoost')\n",
    "LGBM_PATH = os.path.join(BASE_PATH, 'LightGBM')\n",
    "COMPARE_PATH = os.path.join(BASE_PATH, 'compairation')\n",
    "DATA_RESULTS_PATH = os.path.join(BASE_PATH, 'data_results')\n",
    "\n",
    "# Create directories\n",
    "# SVM_PATH has been removed\n",
    "paths = [EDA_PATH, STATS_PATH, LR_PATH, RF_PATH, XGB_PATH, LGBM_PATH, COMPARE_PATH, DATA_RESULTS_PATH]\n",
    "for path in paths:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "print(\"All directories are created or already exist.\")\n",
    "\n",
    "# --- Helper Function for Saving Plots ---\n",
    "def save_plot(fig, path, filename, width_cm=13):\n",
    "    \"\"\"Saves a matplotlib figure in multiple formats with specified width.\"\"\"\n",
    "    # Convert width from cm to inches\n",
    "    width_in = width_cm / 2.54\n",
    "    # Adjust height to maintain aspect ratio\n",
    "    fig.set_size_inches(width_in, fig.get_figheight() * (width_in / fig.get_figwidth()))\n",
    "    # Save the figure\n",
    "    fig.savefig(os.path.join(path, f\"{filename}.svg\"), format='svg', bbox_inches='tight')\n",
    "    fig.savefig(os.path.join(path, f\"{filename}.pdf\"), format='pdf', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"Plot saved: {filename}.svg and {filename}.pdf in {path}\")\n",
    "\n",
    "# --- Load and Prepare Data ---\n",
    "try:\n",
    "    # Changed to read_excel for .xlsx files\n",
    "    df = pd.read_excel(DATA_PATH)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {DATA_PATH}\")\n",
    "    exit()\n",
    "\n",
    "def clean_col_names(df):\n",
    "    \"\"\"Cleans column names to be Python-friendly.\"\"\"\n",
    "    cols = df.columns\n",
    "    new_cols = []\n",
    "    for col in cols:\n",
    "        new_col = col.strip()\n",
    "        new_col = re.sub(r'[\\s\\(\\)-]+', '_', new_col) # Replace special characters with underscore\n",
    "        new_col = new_col.lower().rstrip('_')\n",
    "        new_cols.append(new_col)\n",
    "    df.columns = new_cols\n",
    "    return df\n",
    "\n",
    "df = clean_col_names(df)\n",
    "df.to_excel(os.path.join(DATA_RESULTS_PATH, 'source_data_for_eda_plots.xlsx'), index=False)\n",
    "print(f\"Source data for EDA saved to: {DATA_RESULTS_PATH}\")\n",
    "print(\"\\nDataset loaded successfully. Column names cleaned.\")\n",
    "print(df.head())\n",
    "\n",
    "# ==============================================================================\n",
    "# Step 1: Exploratory Data Analysis (EDA)\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Step 1: Starting Exploratory Data Analysis (EDA)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Descriptive statistics\n",
    "desc_stats = df.groupby('class').describe().transpose()\n",
    "desc_stats.to_excel(os.path.join(EDA_PATH, 'descriptive_statistics_by_class.xlsx'))\n",
    "desc_stats.to_excel(os.path.join(DATA_RESULTS_PATH, 'eda_descriptive_statistics.xlsx'))\n",
    "print(\"\\nDescriptive statistics saved to EDA and data_results folders.\")\n",
    "\n",
    "# Identify features to plot\n",
    "numeric_features = df.select_dtypes(include=np.number).columns.tolist()\n",
    "target_col = 'class'\n",
    "features_to_plot = [col for col in df.columns if col != target_col]\n",
    "\n",
    "print(\"\\nGenerating Box Plots...\")\n",
    "for feature in features_to_plot:\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    sns.boxplot(x=target_col, y=feature, data=df, ax=ax)\n",
    "    ax.set_title(f'Distribution of {feature} by Class', fontsize=10, fontweight='bold')\n",
    "    ax.set_xlabel('Class', fontsize=8)\n",
    "    ax.set_ylabel(feature, fontsize=8)\n",
    "    ax.tick_params(axis='x', rotation=0, labelsize=8)\n",
    "    ax.tick_params(axis='y', labelsize=8)\n",
    "    ax.grid(True, which='major', axis='y', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    save_plot(fig, EDA_PATH, f'boxplot_{feature}')\n",
    "\n",
    "print(\"\\nGenerating Correlation Matrix...\")\n",
    "correlation_matrix = df[features_to_plot].corr()\n",
    "correlation_matrix.to_excel(os.path.join(DATA_RESULTS_PATH, 'eda_correlation_matrix_data.xlsx'))\n",
    "print(f\"Correlation matrix data saved to: {DATA_RESULTS_PATH}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(24, 20)) # Increased size for 28 features\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.1f', cmap='coolwarm', ax=ax, annot_kws={\"size\": 7})\n",
    "ax.set_title('Correlation Matrix of Numeric Features', fontsize=12, fontweight='bold', pad=20)\n",
    "ax.tick_params(axis='x', labelsize=8, labelrotation=90)\n",
    "ax.tick_params(axis='y', labelsize=8, labelrotation=0)\n",
    "save_plot(fig, EDA_PATH, 'correlation_heatmap', width_cm=30)\n",
    "\n",
    "print(\"\\nGenerating Distribution Plots...\")\n",
    "for feature in features_to_plot:\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    sns.histplot(data=df, x=feature, hue=target_col, kde=True, element=\"step\", ax=ax, palette='viridis')\n",
    "    ax.set_title(f'Distribution of {feature} for each Class', fontsize=10, fontweight='bold')\n",
    "    ax.set_xlabel(feature, fontsize=8)\n",
    "    ax.set_ylabel('Count', fontsize=8)\n",
    "    ax.tick_params(labelsize=8)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    legend = ax.get_legend()\n",
    "    if legend:\n",
    "        legend.set_title('Class')\n",
    "        plt.setp(legend.get_texts(), fontsize='8')\n",
    "        plt.setp(legend.get_title(), fontsize='8')\n",
    "    save_plot(fig, EDA_PATH, f'distribution_{feature}')\n",
    "\n",
    "print(\"\\nEDA Step Completed.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# Step 2: Statistical Analysis\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Step 2: Starting Statistical Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "classes = df[target_col].unique()\n",
    "statistical_results = []\n",
    "for feature in features_to_plot:\n",
    "    grouped_data = [df[df[target_col] == c][feature].dropna() for c in classes]\n",
    "    \n",
    "    # Shapiro-Wilk test for normality\n",
    "    is_normal_all_groups = True\n",
    "    for g in grouped_data:\n",
    "        if len(g) > 3:\n",
    "            sample_size = min(len(g), 4999) # Shapiro test limit\n",
    "            _, p_val = shapiro(g.sample(sample_size, random_state=42))\n",
    "            if p_val < 0.05:\n",
    "                is_normal_all_groups = False\n",
    "                break\n",
    "        else:\n",
    "            is_normal_all_groups = False\n",
    "            break\n",
    "\n",
    "    # Perform ANOVA or Kruskal-Wallis test\n",
    "    if is_normal_all_groups:\n",
    "        test_name = 'ANOVA'\n",
    "        stat, p_value = f_oneway(*grouped_data)\n",
    "    else:\n",
    "        test_name = 'Kruskal-Wallis'\n",
    "        stat, p_value = kruskal(*grouped_data)\n",
    "        \n",
    "    result = {'Feature': feature, 'Test Used': test_name, 'Statistic': stat, 'P-Value': p_value}\n",
    "    statistical_results.append(result)\n",
    "    \n",
    "    # Post-hoc test if significant\n",
    "    if p_value < 0.05 and len(classes) > 2: # Post-hoc is for more than 2 groups\n",
    "        posthoc_df = sp.posthoc_dunn(df, val_col=feature, group_col=target_col, p_adjust='bonferroni')\n",
    "        posthoc_df.to_excel(os.path.join(STATS_PATH, f'posthoc_dunn_{feature}.xlsx'))\n",
    "        posthoc_df.to_excel(os.path.join(DATA_RESULTS_PATH, f'stats_posthoc_dunn_{feature}.xlsx'))\n",
    "\n",
    "stats_df = pd.DataFrame(statistical_results)\n",
    "stats_df.to_excel(os.path.join(STATS_PATH, 'main_statistical_test_results.xlsx'), index=False)\n",
    "stats_df.to_excel(os.path.join(DATA_RESULTS_PATH, 'stats_main_test_results.xlsx'), index=False)\n",
    "print(\"\\nStatistical analysis completed. All result data saved to data_results folder.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# Step 3: Machine Learning Modeling\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Step 3: Starting Machine Learning Modeling\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X = df[features_to_plot]\n",
    "y_raw = df[target_col]\n",
    "\n",
    "# Encode target labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_raw)\n",
    "n_classes = len(le.classes_)\n",
    "np.savetxt(os.path.join(DATA_RESULTS_PATH, 'ml_label_encoder_classes.txt'), le.classes_, fmt='%s')\n",
    "joblib.dump(le, os.path.join(DATA_RESULTS_PATH, 'ml_label_encoder.joblib'))\n",
    "print(f\"\\nTarget classes encoded and encoder saved: {list(le.classes_)} -> {list(range(n_classes))}\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "joblib.dump(scaler, os.path.join(DATA_RESULTS_PATH, 'ml_standard_scaler.joblib'))\n",
    "\n",
    "# Save unscaled test data for re-plotting\n",
    "X_test_df = pd.DataFrame(X_test, columns=features_to_plot)\n",
    "y_test_df = pd.DataFrame({'y_test_encoded': y_test, 'y_test_class_name': le.inverse_transform(y_test)}, index=X_test_df.index)\n",
    "test_data_to_save = pd.concat([X_test_df, y_test_df], axis=1)\n",
    "test_data_to_save.to_excel(os.path.join(DATA_RESULTS_PATH, 'ml_test_data_unscaled.xlsx'), index=False)\n",
    "print(\"\\nUnscaled test data and scaler saved for re-plotting purposes.\")\n",
    "\n",
    "# Define models (SVM removed)\n",
    "models = {\n",
    "    'Logistic_Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random_Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    'LightGBM': LGBMClassifier(random_state=42)\n",
    "}\n",
    "model_paths = {'Logistic_Regression': LR_PATH, 'Random_Forest': RF_PATH, 'XGBoost': XGB_PATH, 'LightGBM': LGBM_PATH}\n",
    "all_metrics = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n--- Processing Model: {name} ---\")\n",
    "    output_path = model_paths[name]\n",
    "    \n",
    "    # Fit model and make predictions\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics for binary classification\n",
    "    metrics = {\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred, average='binary'),\n",
    "        'Recall': recall_score(y_test, y_pred, average='binary'),\n",
    "        'F1-score': f1_score(y_test, y_pred, average='binary'),\n",
    "        'Cohen\\'s Kappa': cohen_kappa_score(y_test, y_pred),\n",
    "        'Matthews Corr Coef': matthews_corrcoef(y_test, y_pred),\n",
    "        'ROC AUC': roc_auc_score(y_test, y_pred_proba[:, 1]),\n",
    "    }\n",
    "    all_metrics.append(metrics)\n",
    "    \n",
    "    # Save metrics and model\n",
    "    pd.DataFrame([metrics]).to_excel(os.path.join(output_path, f'{name}_evaluation_metrics.xlsx'), index=False)\n",
    "    joblib.dump(model, os.path.join(output_path, f'{name}_model.joblib'))\n",
    "    print(f\"Evaluation metrics and model saved for {name}.\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_df = pd.DataFrame(cm, index=le.classes_, columns=le.classes_)\n",
    "    cm_df.to_excel(os.path.join(DATA_RESULTS_PATH, f'ml_confusion_matrix_data_{name}.xlsx'))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', ax=ax, annot_kws={\"size\": 10})\n",
    "    ax.set_title(f'Confusion Matrix - {name}', fontsize=12, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Predicted Label', fontsize=10)\n",
    "    ax.set_ylabel('True Label', fontsize=10)\n",
    "    ax.tick_params(axis='x', labelsize=8)\n",
    "    ax.tick_params(axis='y', labelsize=8, rotation=0)\n",
    "    save_plot(fig, output_path, f'{name}_confusion_matrix', width_cm=15)\n",
    "    \n",
    "    # SHAP Analysis\n",
    "    print(f\"Performing SHAP analysis for {name}...\")\n",
    "    if name in ['Random_Forest', 'XGBoost', 'LightGBM']:\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_test_scaled)\n",
    "    else: # Logistic Regression\n",
    "        explainer = shap.LinearExplainer(model, X_train_scaled)\n",
    "        shap_values = explainer.shap_values(X_test_scaled)\n",
    "\n",
    "    # For binary classification, shap_values can be a single array or a list of two.\n",
    "    # We plot for the positive class (class 1).\n",
    "    shap_values_positive_class = shap_values[1] if isinstance(shap_values, list) else shap_values\n",
    "\n",
    "    X_test_df_for_shap = pd.DataFrame(X_test_scaled, columns=features_to_plot)\n",
    "\n",
    "    shap.summary_plot(\n",
    "        shap_values_positive_class, \n",
    "        X_test_df_for_shap, \n",
    "        show=False,\n",
    "        plot_size=(15, 12)\n",
    "    )\n",
    "    fig = plt.gcf()\n",
    "    fig.suptitle(f'SHAP Feature Importance for Class \"{le.classes_[1]}\" - {name}', fontsize=12, fontweight='bold', y=1.0)\n",
    "    fig.tight_layout(pad=2.0)\n",
    "    save_plot(fig, output_path, f'{name}_shap_summary_plot', width_cm=25)\n",
    "\n",
    "print(\"\\nMachine Learning modeling step completed.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# Step 4: Model Comparison\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Step 4: Starting Model Comparison\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_metrics_df = pd.DataFrame(all_metrics).set_index('Model')\n",
    "all_metrics_df.to_excel(os.path.join(COMPARE_PATH, 'all_models_comparison_metrics.xlsx'))\n",
    "all_metrics_df.to_excel(os.path.join(DATA_RESULTS_PATH, 'comparison_all_models_metrics.xlsx'))\n",
    "print(\"Comparison metrics data saved.\")\n",
    "print(all_metrics_df)\n",
    "\n",
    "# Bar chart for key metrics\n",
    "metrics_to_compare = ['Accuracy', 'F1-score', 'ROC AUC']\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "all_metrics_df[metrics_to_compare].plot(kind='bar', ax=ax, rot=0, width=0.7)\n",
    "ax.set_title('Comparison of Key Metrics Across Models', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Score', fontsize=10)\n",
    "ax.set_xlabel('Model', fontsize=10)\n",
    "ax.set_ylim(0.8, 1.0)\n",
    "ax.tick_params(axis='x', labelsize=9)\n",
    "ax.tick_params(axis='y', labelsize=9)\n",
    "ax.legend(title='Metric', fontsize=9, title_fontsize='9')\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "save_plot(fig, COMPARE_PATH, 'models_metrics_comparison_bar_chart')\n",
    "\n",
    "# --- Comparative ROC Curves ---\n",
    "fig_roc, ax_roc = plt.subplots(figsize=(8, 8))\n",
    "for name, model in models.items():\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    roc_data_df = pd.DataFrame({'fpr': fpr, 'tpr': tpr})\n",
    "    roc_data_df.to_excel(os.path.join(DATA_RESULTS_PATH, f'comparison_roc_curve_data_{name}.xlsx'), index=False)\n",
    "    \n",
    "    ax_roc.plot(fpr, tpr, lw=2, label=f'{name} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "ax_roc.plot([0, 1], [0, 1], 'k--', lw=2, label='Chance')\n",
    "ax_roc.set_xlim([0.0, 1.0]); ax_roc.set_ylim([0.0, 1.05])\n",
    "ax_roc.set_xlabel('False Positive Rate', fontsize=10)\n",
    "ax_roc.set_ylabel('True Positive Rate', fontsize=10)\n",
    "ax_roc.set_title('Comparative ROC Curves', fontsize=12, fontweight='bold')\n",
    "ax_roc.legend(loc=\"lower right\", fontsize=9)\n",
    "ax_roc.tick_params(labelsize=9)\n",
    "ax_roc.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "ax_roc.set_aspect('equal', adjustable='box')\n",
    "save_plot(fig_roc, COMPARE_PATH, 'all_models_roc_curves', width_cm=15)\n",
    "\n",
    "# --- Comparative Precision-Recall Curves ---\n",
    "print(\"\\nGenerating Comparative Precision-Recall Curves...\")\n",
    "fig_pr, ax_pr = plt.subplots(figsize=(8, 8))\n",
    "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "ax_pr.plot([0, 1], [no_skill, no_skill], 'k--', lw=2, label=f'No-Skill (AP={no_skill:.3f})')\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    avg_precision = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "    pr_data_df = pd.DataFrame({'recall': recall, 'precision': precision})\n",
    "    pr_data_df.to_excel(os.path.join(DATA_RESULTS_PATH, f'comparison_pr_curve_data_{name}.xlsx'), index=False)\n",
    "\n",
    "    ax_pr.plot(recall, precision, lw=2, label=f'{name} (AP = {avg_precision:.3f})')\n",
    "\n",
    "ax_pr.set_xlim([0.0, 1.0]); ax_pr.set_ylim([0.0, 1.05])\n",
    "ax_pr.set_xlabel('Recall', fontsize=10)\n",
    "ax_pr.set_ylabel('Precision', fontsize=10)\n",
    "ax_pr.set_title('Comparative Precision-Recall Curves', fontsize=12, fontweight='bold')\n",
    "ax_pr.legend(loc=\"lower left\", fontsize=9)\n",
    "ax_pr.tick_params(labelsize=9)\n",
    "ax_pr.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "ax_pr.set_aspect('equal', adjustable='box')\n",
    "save_plot(fig_pr, COMPARE_PATH, 'all_models_pr_curves', width_cm=15)\n",
    "\n",
    "print(\"\\nModel comparison step completed.\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SCRIPT EXECUTION FINISHED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422d28b2",
   "metadata": {},
   "source": [
    "Reproduce Figures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f76f67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# کد 2: اسکریپت بازتولید نمودارها از نتایج ذخیره‌شده\n",
    "# ==============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import joblib\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "\n",
    "# --- Configuration ---\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# --- Define Paths (باید با اسکریپت اصلی یکسان باشد) ---\n",
    "BASE_PATH = '/home/sajad/Sajad_test/Pistachio Dataset/'\n",
    "LR_PATH = os.path.join(BASE_PATH, 'Logistic_Regression')\n",
    "RF_PATH = os.path.join(BASE_PATH, 'Random_Forest')\n",
    "XGB_PATH = os.path.join(BASE_PATH, 'XGBoost')\n",
    "LGBM_PATH = os.path.join(BASE_PATH, 'LightGBM')\n",
    "COMPARE_PATH = os.path.join(BASE_PATH, 'compairation')\n",
    "DATA_RESULTS_PATH = os.path.join(BASE_PATH, 'data_results')\n",
    "\n",
    "# --- Helper Function for Saving Plots ---\n",
    "def save_plot(fig, path, filename, width_cm=13):\n",
    "    \"\"\"Saves a matplotlib figure in multiple formats with specified width.\"\"\"\n",
    "    width_in = width_cm / 2.54\n",
    "    fig.set_size_inches(width_in, fig.get_figheight() * (width_in / fig.get_figwidth()))\n",
    "    fig.savefig(os.path.join(path, f\"{filename}.svg\"), format='svg', bbox_inches='tight')\n",
    "    fig.savefig(os.path.join(path, f\"{filename}.pdf\"), format='pdf', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"Re-plotted and saved: {filename}.svg and {filename}.pdf in {path}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# Step 1: Load Pre-computed Data and Saved Models\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Step 1: Loading all necessary pre-computed data and models...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    # Load essential components\n",
    "    le = joblib.load(os.path.join(DATA_RESULTS_PATH, 'ml_label_encoder.joblib'))\n",
    "    scaler = joblib.load(os.path.join(DATA_RESULTS_PATH, 'ml_standard_scaler.joblib'))\n",
    "    test_data = pd.read_excel(os.path.join(DATA_RESULTS_PATH, 'ml_test_data_unscaled.xlsx'))\n",
    "    all_metrics_df = pd.read_excel(os.path.join(DATA_RESULTS_PATH, 'comparison_all_models_metrics.xlsx'), index_col=0)\n",
    "    \n",
    "    # Separate test data\n",
    "    features_to_plot = [col for col in test_data.columns if col not in ['y_test_encoded', 'y_test_class_name']]\n",
    "    X_test = test_data[features_to_plot]\n",
    "    y_test = test_data['y_test_encoded'].values\n",
    "    \n",
    "    # Scale test data for models\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    print(\"All necessary files loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading files: {e}\")\n",
    "    print(\"Please run the main script first to generate the results.\")\n",
    "    exit()\n",
    "\n",
    "# Define models and paths (SVM removed)\n",
    "models_to_plot = {\n",
    "    'Logistic_Regression': LR_PATH,\n",
    "    'Random_Forest': RF_PATH,\n",
    "    'XGBoost': XGB_PATH,\n",
    "    'LightGBM': LGBM_PATH\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# Step 2: Re-generate Plots for Each Model\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Step 2: Re-generating plots for each model...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for name, output_path in models_to_plot.items():\n",
    "    print(f\"\\n--- Re-plotting for Model: {name} ---\")\n",
    "    \n",
    "    # Load the saved model\n",
    "    model = joblib.load(os.path.join(output_path, f'{name}_model.joblib'))\n",
    "    \n",
    "    # Re-generate Confusion Matrix Plot\n",
    "    cm_df = pd.read_excel(os.path.join(DATA_RESULTS_PATH, f'ml_confusion_matrix_data_{name}.xlsx'), index_col=0)\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', ax=ax, annot_kws={\"size\": 10})\n",
    "    ax.set_title(f'Confusion Matrix - {name}', fontsize=12, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Predicted Label', fontsize=10)\n",
    "    ax.set_ylabel('True Label', fontsize=10)\n",
    "    ax.tick_params(axis='x', labelsize=8)\n",
    "    ax.tick_params(axis='y', labelsize=8, rotation=0)\n",
    "    save_plot(fig, output_path, f'{name}_confusion_matrix', width_cm=15)\n",
    "    \n",
    "    # Re-calculate and Re-generate SHAP Plots\n",
    "    print(f\"Re-calculating SHAP values for {name}...\")\n",
    "    if name in ['Random_Forest', 'XGBoost', 'LightGBM']:\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_test_scaled)\n",
    "    else: # Logistic Regression\n",
    "        # Re-load training data just for SHAP background\n",
    "        X_train_scaled_for_shap = scaler.transform(pd.read_excel(DATA_PATH).drop('CLASS', axis=1, errors='ignore'))\n",
    "        background_data = shap.sample(X_train_scaled_for_shap, 100)\n",
    "        explainer = shap.LinearExplainer(model, background_data)\n",
    "        shap_values = explainer.shap_values(X_test_scaled)\n",
    "        \n",
    "    shap_values_positive_class = shap_values[1] if isinstance(shap_values, list) else shap_values\n",
    "\n",
    "    X_test_df_for_shap = pd.DataFrame(X_test_scaled, columns=features_to_plot)\n",
    "\n",
    "    shap.summary_plot(\n",
    "        shap_values_positive_class, \n",
    "        X_test_df_for_shap, \n",
    "        show=False,\n",
    "        plot_size=(15, 12)\n",
    "    )\n",
    "    fig = plt.gcf()\n",
    "    fig.suptitle(f'SHAP Feature Importance for Class \"{le.classes_[1]}\" - {name}', fontsize=12, fontweight='bold', y=1.0)\n",
    "    fig.tight_layout(pad=2.0)\n",
    "    save_plot(fig, output_path, f'{name}_shap_summary_plot', width_cm=25)\n",
    "\n",
    "# ==============================================================================\n",
    "# Step 3: Re-generate Comparison Plots\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Step 3: Re-generating comparison plots...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Bar chart for key metrics\n",
    "metrics_to_compare = ['Accuracy', 'F1-score', 'ROC AUC']\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "all_metrics_df[metrics_to_compare].plot(kind='bar', ax=ax, rot=0, width=0.7)\n",
    "ax.set_title('Comparison of Key Metrics Across Models', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Score', fontsize=10)\n",
    "ax.set_xlabel('Model', fontsize=10)\n",
    "ax.set_ylim(0.8, 1.0)\n",
    "ax.tick_params(axis='x', labelsize=9)\n",
    "ax.tick_params(axis='y', labelsize=9)\n",
    "ax.legend(title='Metric', fontsize=9, title_fontsize='9')\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "save_plot(fig, COMPARE_PATH, 'models_metrics_comparison_bar_chart')\n",
    "\n",
    "# --- Comparative ROC Curves ---\n",
    "fig_roc, ax_roc = plt.subplots(figsize=(8, 8))\n",
    "for name in models_to_plot.keys():\n",
    "    roc_data_df = pd.read_excel(os.path.join(DATA_RESULTS_PATH, f'comparison_roc_curve_data_{name}.xlsx'))\n",
    "    roc_auc = auc(roc_data_df['fpr'], roc_data_df['tpr'])\n",
    "    ax_roc.plot(roc_data_df['fpr'], roc_data_df['tpr'], lw=2, label=f'{name} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "ax_roc.plot([0, 1], [0, 1], 'k--', lw=2, label='Chance')\n",
    "ax_roc.set_xlim([0.0, 1.0]); ax_roc.set_ylim([0.0, 1.05])\n",
    "ax_roc.set_xlabel('False Positive Rate', fontsize=10)\n",
    "ax_roc.set_ylabel('True Positive Rate', fontsize=10)\n",
    "ax_roc.set_title('Comparative ROC Curves', fontsize=12, fontweight='bold')\n",
    "ax_roc.legend(loc=\"lower right\", fontsize=9)\n",
    "ax_roc.tick_params(labelsize=9)\n",
    "ax_roc.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "ax_roc.set_aspect('equal', adjustable='box')\n",
    "save_plot(fig_roc, COMPARE_PATH, 'all_models_roc_curves', width_cm=15)\n",
    "\n",
    "# --- Comparative Precision-Recall Curves ---\n",
    "fig_pr, ax_pr = plt.subplots(figsize=(8, 8))\n",
    "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "ax_pr.plot([0, 1], [no_skill, no_skill], 'k--', lw=2, label=f'No-Skill (AP={no_skill:.3f})')\n",
    "\n",
    "for name in models_to_plot.keys():\n",
    "    pr_data_df = pd.read_excel(os.path.join(DATA_RESULTS_PATH, f'comparison_pr_curve_data_{name}.xlsx'))\n",
    "    avg_precision = auc(pr_data_df['recall'], pr_data_df['precision'])\n",
    "    ax_pr.plot(pr_data_df['recall'], pr_data_df['precision'], lw=2, label=f'{name} (AP = {avg_precision:.3f})')\n",
    "\n",
    "ax_pr.set_xlim([0.0, 1.0]); ax_pr.set_ylim([0.0, 1.05])\n",
    "ax_pr.set_xlabel('Recall', fontsize=10)\n",
    "ax_pr.set_ylabel('Precision', fontsize=10)\n",
    "ax_pr.set_title('Comparative Precision-Recall Curves', fontsize=12, fontweight='bold')\n",
    "ax_pr.legend(loc=\"lower left\", fontsize=9)\n",
    "ax_pr.tick_params(labelsize=9)\n",
    "ax_pr.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "ax_pr.set_aspect('equal', adjustable='box')\n",
    "save_plot(fig_pr, COMPARE_PATH, 'all_models_pr_curves', width_cm=15)\n",
    "\n",
    "print(\"\\nRe-plotting process completed successfully!\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RE-PLOTTING SCRIPT FINISHED!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
